{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的音乐推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:11.370372Z",
     "start_time": "2019-08-30T08:24:09.510473Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import re\n",
    "import time\n",
    "import shutil\n",
    "import warnings\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:11.411758Z",
     "start_time": "2019-08-30T08:24:11.372961Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wangwei/tf_workdir/movie_rec\n",
      "['data_vec', 'checkpoint', 'movie_rec.ipynb', 'movie_rec_bak.ipynb', '.ipynb_checkpoints', 'save.data-00000-of-00001', 'save.meta', 'runs', 'ml-1m', 'model', 'save.index']\n",
      "/home/wangwei/tf_workdir/movie_rec ['data_vec', '.ipynb_checkpoints', 'runs', 'ml-1m', 'model'] ['checkpoint', 'movie_rec.ipynb', 'movie_rec_bak.ipynb', 'save.data-00000-of-00001', 'save.meta', 'save.index']\n",
      "/home/wangwei/tf_workdir/movie_rec/data_vec [] ['user_vec.txt', 'movie_vec.txt']\n",
      "/home/wangwei/tf_workdir/movie_rec/.ipynb_checkpoints [] ['movie_rec_bak-checkpoint.ipynb']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs ['1567127559', '1567139905', '1567127218', '1567153017', '.ipynb_checkpoints'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567127559 ['summaries'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567127559/summaries ['train', 'test'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567127559/summaries/train [] ['events.out.tfevents.1567127559.user-IW4200-8G']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567127559/summaries/test [] ['events.out.tfevents.1567127559.user-IW4200-8G']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567139905 ['summaries'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567139905/summaries ['train', 'test'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567139905/summaries/train [] ['events.out.tfevents.1567139905.user-IW4200-8G']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567139905/summaries/test [] ['events.out.tfevents.1567139905.user-IW4200-8G']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567127218 ['summaries'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567127218/summaries ['train', 'test'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567127218/summaries/train [] ['events.out.tfevents.1567127218.user-IW4200-8G']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567127218/summaries/test [] ['events.out.tfevents.1567127218.user-IW4200-8G']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567153017 ['summaries'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567153017/summaries ['train', 'test'] []\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567153017/summaries/train [] ['events.out.tfevents.1567153018.user-IW4200-8G']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/1567153017/summaries/test [] ['events.out.tfevents.1567153018.user-IW4200-8G']\n",
      "/home/wangwei/tf_workdir/movie_rec/runs/.ipynb_checkpoints [] []\n",
      "/home/wangwei/tf_workdir/movie_rec/ml-1m [] ['movies.dat', 'users.dat', 'ratings.dat', 'README']\n",
      "/home/wangwei/tf_workdir/movie_rec/model [] ['checkpoint', 'model.ckpt.data-00000-of-00001', 'model.ckpt.meta', 'model.ckpt.index']\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/home/wangwei/tf_workdir/movie_rec\"\n",
    "print(os.getcwd())\n",
    "print(os.listdir(os.getcwd()))\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    print(root, dirs, files)\n",
    "# 递归删除目录 \n",
    "# shutil.rmtree(\"/home/wangwei/tf_workdir/movie_recommender/ml-1m\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:11.471338Z",
     "start_time": "2019-08-30T08:24:11.414454Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>OccupationID</th>\n",
       "      <th>Zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  OccupationID Zip-code\n",
       "0       1      F    1            10    48067\n",
       "1       2      M   56            16    70072\n",
       "2       3      M   25            15    55117\n",
       "3       4      M   45             7    02460\n",
       "4       5      M   25            20    55455"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# 读取用户数据\n",
    "# 用户ID、性别、年龄、职业ID和邮编\n",
    "users_title = ['UserID', 'Gender', 'Age', 'OccupationID', 'Zip-code']\n",
    "users = pd.read_table(os.path.join(file_path, \"ml-1m/users.dat\"), names=users_title, sep=\"::\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:11.497621Z",
     "start_time": "2019-08-30T08:24:11.473303Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# 读取电影数据\n",
    "# 电影ID、电影名和电影风格等字段。\n",
    "movies_title = ['MovieID', 'Title', 'Genres']\n",
    "movies = pd.read_table(os.path.join(file_path, \"ml-1m/movies.dat\"), names=movies_title, sep=\"::\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:17.104863Z",
     "start_time": "2019-08-30T08:24:11.499239Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  timestamps\n",
       "0       1     1193       5   978300760\n",
       "1       1      661       3   978302109\n",
       "2       1      914       3   978301968\n",
       "3       1     3408       4   978300275\n",
       "4       1     2355       5   978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# 评分数据\n",
    "# 用户ID、电影ID、评分和时间戳\n",
    "ratings_title = ['UserID','MovieID', 'Rating', 'timestamps']\n",
    "ratings = pd.read_table(os.path.join(file_path, \"ml-1m/ratings.dat\"), names=ratings_title, sep='::')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行数据预处理\n",
    "- Gender映射到[0, 1]\n",
    "- Age映射到[0, 6]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:17.110398Z",
     "start_time": "2019-08-30T08:24:17.107432Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 性别字典\n",
    "gender_map = {\"F\": 0, \"M\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:17.124388Z",
     "start_time": "2019-08-30T08:24:17.111916Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 18: 4, 25: 6, 35: 1, 45: 2, 50: 3, 56: 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 年龄字典\n",
    "age_map = {value: id for id, value in enumerate(set(users[\"Age\"]))}\n",
    "age_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:17.134558Z",
     "start_time": "2019-08-30T08:24:17.128351Z"
    }
   },
   "outputs": [],
   "source": [
    "# 进行浅拷贝\n",
    "movies_source =  movies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:17.144152Z",
     "start_time": "2019-08-30T08:24:17.137242Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 删除年份(1996)\n",
    "s = \"Grumpier Old Men (1995)\"\n",
    "r_s = re.sub(\"\\(\\d+\\)\", \"\", s).strip()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:17.555469Z",
     "start_time": "2019-08-30T08:24:17.146465Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>OccupationID</th>\n",
       "      <th>Zip-code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>32793</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978199279</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>22903</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978158471</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>95350</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  timestamps  Gender  Age  OccupationID Zip-code  \\\n",
       "0       1     1193       5   978300760       0    0            10    48067   \n",
       "1       2     1193       5   978298413       1    5            16    70072   \n",
       "2      12     1193       4   978220179       1    6            12    32793   \n",
       "3      15     1193       4   978199279       1    6             7    22903   \n",
       "4      17     1193       5   978158471       1    3             1    95350   \n",
       "\n",
       "                                               Title                    Genres  \n",
       "0  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  \n",
       "1  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  \n",
       "2  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  \n",
       "3  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  \n",
       "4  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_process(users, movies, ratings):\n",
    "    users[\"Gender\"] = users[\"Gender\"].map(gender_map)\n",
    "    users[\"Age\"] = users[\"Age\"].map(age_map)\n",
    "    movies[\"Title\"] = movies[\"Title\"].map(lambda x: re.sub(\"\\(\\d+\\)\", \"\", x).strip())\n",
    "    \n",
    "    def seq_process(df, col, sep):\n",
    "        '''\n",
    "        :param df: 传入dataframe\n",
    "        :param col: 传入列名\n",
    "        :param sep: 传入分隔符\n",
    "        :return: 返回等长的映射id序列\n",
    "        '''\n",
    "        col_set = set()\n",
    "        col_max_len = 0\n",
    "        source_sep_list = []\n",
    "        for val in df[col].values:\n",
    "            sep_l = val.split(sep)\n",
    "            col_set.update(sep_l)\n",
    "            source_sep_list.append(sep_l)\n",
    "            if len(sep_l) > col_max_len:\n",
    "                col_max_len = len(sep_l)\n",
    "        # 长度不足时，增加<PAD>\n",
    "        col_set.add('<PAD>')\n",
    "        col2id = {value: id for id, value in enumerate(col_set)}\n",
    "        dest_sep_list = [[col2id[t] for t in l] + [col2id[\"<PAD>\"]] * (col_max_len - len(l)) for l in source_sep_list]\n",
    "        df[col] = dest_sep_list\n",
    "#         print(col + \"列的最大长度序列为：\", col_max_len)\n",
    "#         print(col + \"列的字典表为：\", col2id)\n",
    "        return df, col2id, col_max_len\n",
    "    movies, title2id, title_maxlen = seq_process(movies, \"Title\", \" \")\n",
    "    movies, genre2id, genre_maxlen = seq_process(movies, \"Genres\", \"|\")\n",
    "    \n",
    "    # 合并三个数据集\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    return data, title2id, title_maxlen, genre2id, genre_maxlen\n",
    "\n",
    "data, title2id, title_maxlen, genre2id, genre_maxlen = data_process(users, movies, ratings)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:17.561706Z",
     "start_time": "2019-08-30T08:24:17.557349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user number:  6040\n",
      "movie number:  3883\n"
     ]
    }
   ],
   "source": [
    "print(\"user number: \", len(users))\n",
    "print(\"movie number: \", len(movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义generate batch函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:17.957542Z",
     "start_time": "2019-08-30T08:24:17.563352Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        UserID  MovieID  Rating  timestamps  Gender  Age  OccupationID  \\\n",
      "136800    2092      593       4   974653158       1    5             1   \n",
      "809312    1162     3200       4   974864335       0    1             0   \n",
      "967469    6040      759       5   956704448       1    6             6   \n",
      "\n",
      "       Zip-code                                              Title  \\\n",
      "136800    49006  [5075, 848, 3739, 3642, 111, 3791, 3791, 3791,...   \n",
      "809312    97213  [3585, 387, 111, 3791, 3791, 3791, 3791, 3791,...   \n",
      "967469    11106  [1425, 417, 1179, 4856, 3174, 4735, 3791, 3791...   \n",
      "\n",
      "                          Genres  \n",
      "136800   [13, 2, 14, 14, 14, 14]  \n",
      "809312  [10, 13, 14, 14, 14, 14]  \n",
      "967469  [16, 14, 14, 14, 14, 14]  \n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集， 同时生成batch data\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=123)\n",
    "# 或者\n",
    "# train=data.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "# test=data.drop(train.index)\n",
    "def get_batches(Xs, batch_size):\n",
    "    for start in range(0, len(Xs), batch_size):\n",
    "        end = min(start + batch_size, len(Xs))\n",
    "        yield Xs[start:end]\n",
    "batch_data = next(get_batches(train, 3))\n",
    "print(batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数设置与各项词汇统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:18.007319Z",
     "start_time": "2019-08-30T08:24:17.959738Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UserID', 'MovieID', 'Rating', 'timestamps', 'Gender', 'Age',\n",
      "       'OccupationID', 'Zip-code', 'Title', 'Genres'],\n",
      "      dtype='object')\n",
      "5215 19\n",
      "15 6\n"
     ]
    }
   ],
   "source": [
    "# 开始构建模型\n",
    "# 统计各个特征的数目\n",
    "print(data.columns)\n",
    "# Index(['UserID', 'MovieID', 'Rating', 'timestamps', 'Gender', 'Age',\n",
    "# 'OccupationID', 'Zip-code', 'Title', 'Genres'], dtype='object')\n",
    "# user info \n",
    "vocab_uid = max(data[\"UserID\"].unique()) + 1\n",
    "vocab_gender = max(data[\"Gender\"].unique()) + 1\n",
    "vocab_age = max(data[\"Age\"].unique()) + 1\n",
    "vocab_job = max(data[\"OccupationID\"].unique()) + 1\n",
    "\n",
    "# movie info \n",
    "vocab_mid = max(data[\"MovieID\"].unique()) + 1\n",
    "\n",
    "vocab_title = len(title2id) \n",
    "vocab_genre = len(genre2id)\n",
    "print(vocab_title, vocab_genre)\n",
    "print(title_maxlen, genre_maxlen)\n",
    "\n",
    "# 参数设置\n",
    "emb_dim = 128\n",
    "hidden_size = 256\n",
    "genre_f = \"sum\" # (or mean)\n",
    "filter_sizes = [2, 3, 4, 5] # 滑动2,3,4,5个单词\n",
    "num_filters = 8 # 卷积核数\n",
    "dropout_keep_prob = 0.5\n",
    "lr = 0.001\n",
    "num_epochs = 5\n",
    "batch_size = 256 \n",
    "display_steps = 600\n",
    "\n",
    "# emb_dim = 32\n",
    "# hidden_size = 200\n",
    "# genre_f = \"sum\" # (or mean)\n",
    "# filter_sizes = [2, 3, 4, 5] # 滑动2,3,4,5个单词\n",
    "# num_filters = 8 # 卷积核数\n",
    "# dropout_keep_prob = 0.5\n",
    "# lr = 0.0001\n",
    "# num_epochs = 5\n",
    "# batch_size = 256 \n",
    "# display_steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:18.037416Z",
     "start_time": "2019-08-30T08:24:18.010318Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    # 定义placeholder\n",
    "    with tf.name_scope(\"input_placeholder\"):\n",
    "        uid = tf.placeholder(tf.int32, shape=[None, 1], name=\"uid\")\n",
    "        gender = tf.placeholder(tf.int32, shape=[None, 1], name=\"user_gender\")\n",
    "        age = tf.placeholder(tf.int32, shape=[None, 1], name=\"user_age\")\n",
    "        job = tf.placeholder(tf.int32, shape=[None, 1], name=\"user_job\")\n",
    "        \n",
    "        mid = tf.placeholder(tf.int32, shape=[None, 1], name=\"mid\")\n",
    "        title = tf.placeholder(tf.int32, shape=[None, 15], name=\"movie_title\")\n",
    "        genre = tf.placeholder(tf.int32, shape=[None, 6], name=\"movie_genre\")\n",
    "        \n",
    "        target = tf.placeholder(tf.float32, shape=[None, 1], name=\"ratings\")\n",
    "    return uid, gender, age, job, mid, title, genre, target\n",
    "\n",
    "def get_user_embedding(uid, gender, age, job):\n",
    "    # 定义用户的embedding矩阵\n",
    "    with tf.name_scope(\"u_embedding\"):\n",
    "        uid_embedding = tf.Variable(tf.random_normal([vocab_uid, emb_dim], 0, 1), name=\"user_embedding\")\n",
    "        uid_embed = tf.nn.embedding_lookup(uid_embedding, uid, name=\"user_embed\")\n",
    "        gender_embedding = tf.Variable(tf.random_normal([vocab_gender, emb_dim // 2], 0, 1), name=\"gender_embedding\")\n",
    "        gender_embed = tf.nn.embedding_lookup(gender_embedding, gender, name=\"gender_embed\")\n",
    "        age_embedding = tf.Variable(tf.random_normal([vocab_age, emb_dim // 2], 0, 1), name=\"age_embedding\")\n",
    "        age_embed = tf.nn.embedding_lookup(age_embedding, age, name=\"age_embed\")\n",
    "        job_embedding = tf.Variable(tf.random_normal([vocab_job, emb_dim // 2], 0, 1), name=\"job_embedding\")\n",
    "        job_embed = tf.nn.embedding_lookup(job_embedding, job, name=\"job_embed\")\n",
    "    return uid_embedding, uid_embed, gender_embedding, gender_embed, age_embedding, age_embed, job_embedding, job_embed\n",
    "\n",
    "def user_nn(uid_embed, gender_embed, age_embed, job_embed):\n",
    "    # 定义用户的context向量\n",
    "    with tf.name_scope(\"user_nn\"):\n",
    "        # uid_embed: (batch_size, seq_len, emb_dim)\n",
    "        uid_fc = tf.layers.dense(uid_embed, emb_dim, activation=tf.nn.relu)\n",
    "        gender_fc = tf.layers.dense(gender_embed, emb_dim, activation=tf.nn.relu)\n",
    "        age_fc = tf.layers.dense(age_embed, emb_dim, activation=tf.nn.relu)\n",
    "        job_fc = tf.layers.dense(job_embed, emb_dim, activation=tf.nn.relu)\n",
    "        \n",
    "        # 对上述数据进行拼接\n",
    "        u_cat = tf.concat([uid_fc, gender_fc, age_fc, job_fc], axis=-1)\n",
    "#         u_cat = tf.nn.tanh(tf.layers.dense(u_cat, hidden_size))\n",
    "        u_cat = tf.layers.dense(u_cat, hidden_size, activation=tf.nn.tanh)\n",
    "        uinfo = tf.reshape(u_cat, [-1, hidden_size])\n",
    "    return uinfo\n",
    "\n",
    "def movie_nn(mid, genre, title):\n",
    "    with tf.name_scope(\"m_embedding\"):\n",
    "        mid_embedding = tf.Variable(tf.random_normal([vocab_mid, emb_dim], 0, 1))\n",
    "        mid_embed = tf.nn.embedding_lookup(mid_embedding, mid)\n",
    "        genre_embedding = tf.Variable(tf.random_normal([vocab_title, emb_dim // 2], 0, 1))\n",
    "        genre_embed = tf.nn.embedding_lookup(genre_embedding, genre)\n",
    "        if genre_f == \"sum\":\n",
    "            genre_embed = tf.reduce_sum(genre_embed, axis=1, keepdims=True)\n",
    "        elif genre_f == \"mean\":\n",
    "            genre_embed = tf.reduce_mean(genre_embed, axis=1, keepdims=True)\n",
    "            \n",
    "        # 关于标题的cnn\n",
    "        with tf.name_scope(\"title_cnn\"):\n",
    "            title_embedding = tf.Variable(tf.random_normal([vocab_title, emb_dim], 0, 1))\n",
    "            title_embed = tf.nn.embedding_lookup(title_embedding, title)    # (batch_size, max_len, embed_size)\n",
    "            # dim expand for cnn\n",
    "            title_embed = tf.expand_dims(title_embed, -1)\n",
    "            \n",
    "            pooled_outputs = []\n",
    "            for i, filter_size in enumerate(filter_sizes):\n",
    "                # 定义卷积核\n",
    "                filter_shape = [filter_size, emb_dim, 1, num_filters]   # [filter_height, filter_width, in_channels, channel_multiplier]\n",
    "                filter_W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1))\n",
    "                filter_b = tf.Variable(tf.constant(0.1, shape=[num_filters]))\n",
    "                \n",
    "                conv = tf.nn.conv2d(title_embed, filter_W, [1, 1, 1, 1], padding=\"VALID\")\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, filter_b))\n",
    "                pooled = tf.nn.max_pool(h, ksize=[1, title_maxlen - filter_size + 1, 1, 1], strides=[1, 1, 1, 1], padding=\"VALID\") # [batch_size, filter_height, filter_width, channel]\n",
    "                # (batch_size, 1, 1, num_filters)\n",
    "                pooled_outputs.append(pooled)\n",
    "                \n",
    "            h_pool = tf.concat(pooled_outputs, -1)\n",
    "            num_filters_total = num_filters * len(filter_sizes)\n",
    "            h_pool_flat = tf.reshape(h_pool, [-1, 1, num_filters_total])\n",
    "            h_dropout = tf.nn.dropout(h_pool_flat, keep_prob=dropout_keep_prob)\n",
    "        \n",
    "    with tf.name_scope(\"m_nn\"):\n",
    "        mid_fc = tf.layers.dense(mid_embed, emb_dim, activation=tf.nn.relu)\n",
    "        genre_fc = tf.layers.dense(genre_embed, emb_dim, activation=tf.nn.relu)  \n",
    "        m_cat = tf.concat([mid_fc, genre_fc, h_dropout], axis=-1)\n",
    "        m_fc = tf.layers.dense(m_cat, hidden_size, activation=tf.nn.tanh)\n",
    "        m_fc = tf.reshape(m_fc, [-1, hidden_size])\n",
    "    return m_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:19.480644Z",
     "start_time": "2019-08-30T08:24:18.039321Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 构造计算图\n",
    "tf.reset_default_graph()\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    uid, gender, age, job, mid, title, genre, target = get_inputs()\n",
    "    uid_embedding, uid_embed, gender_embedding, gender_embed, age_embedding, age_embed, job_embedding, job_embed = get_user_embedding(uid, gender, age, job)\n",
    "    uinfo = user_nn(uid_embed, gender_embed, age_embed, job_embed)\n",
    "    m_fc = movie_nn(mid, genre, title)\n",
    "    # (batch_size, 1)\n",
    "    inference = tf.reduce_sum(tf.multiply(uinfo, m_fc), axis=-1, keepdims=True, name=\"inference\")\n",
    "    loss_op = tf.reduce_mean(tf.losses.mean_squared_error(target, inference))\n",
    "#     loss_op = tf.reduce_mean(tf.square(target-inference))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    train_op = optimizer.minimize(loss_op)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:19.486776Z",
     "start_time": "2019-08-30T08:24:19.482992Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batches(Xs, batch_size):\n",
    "    for start in range(0, len(Xs), batch_size):\n",
    "        end = min(start + batch_size, len(Xs))\n",
    "        yield Xs[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:24:19.514807Z",
     "start_time": "2019-08-30T08:24:19.488178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>OccupationID</th>\n",
       "      <th>Zip-code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>32793</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978199279</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>22903</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978158471</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>95350</td>\n",
       "      <td>[5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...</td>\n",
       "      <td>[13, 14, 14, 14, 14, 14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  timestamps  Gender  Age  OccupationID Zip-code  \\\n",
       "0       1     1193       5   978300760       0    0            10    48067   \n",
       "1       2     1193       5   978298413       1    5            16    70072   \n",
       "2      12     1193       4   978220179       1    6            12    32793   \n",
       "3      15     1193       4   978199279       1    6             7    22903   \n",
       "4      17     1193       5   978158471       1    3             1    95350   \n",
       "\n",
       "                                               Title                    Genres  \n",
       "0  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  \n",
       "1  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  \n",
       "2  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  \n",
       "3  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  \n",
       "4  [5174, 3787, 1673, 3739, 4318, 1383, 3791, 379...  [13, 14, 14, 14, 14, 14]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:29:39.420926Z",
     "start_time": "2019-08-30T08:24:19.516697Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目录：  /home/wangwei/tf_workdir/movie_rec/runs/1567153460\n",
      "2019-08-30 16:24:23: Epoch   0 Batch    0/3125  train_loss=34.847\n",
      "2019-08-30 16:24:32: Epoch   0 Batch  600/3125  train_loss=2.109\n",
      "2019-08-30 16:24:42: Epoch   0 Batch 1200/3125  train_loss=1.259\n",
      "2019-08-30 16:24:51: Epoch   0 Batch 1800/3125  train_loss=1.692\n",
      "2019-08-30 16:25:01: Epoch   0 Batch 2400/3125  train_loss=1.160\n",
      "2019-08-30 16:25:10: Epoch   0 Batch 3000/3125  train_loss=1.114\n",
      "2019-08-30 16:25:13: Epoch   0 Batch    0/781  test_loss=0.921\n",
      "2019-08-30 16:25:23: Epoch   0 Batch  600/781  test_loss=1.056\n",
      "2019-08-30 16:25:26: Epoch   1 Batch    0/3125  train_loss=0.875\n",
      "2019-08-30 16:25:35: Epoch   1 Batch  600/3125  train_loss=0.972\n",
      "2019-08-30 16:25:45: Epoch   1 Batch 1200/3125  train_loss=0.962\n",
      "2019-08-30 16:25:55: Epoch   1 Batch 1800/3125  train_loss=0.914\n",
      "2019-08-30 16:26:05: Epoch   1 Batch 2400/3125  train_loss=0.896\n",
      "2019-08-30 16:26:15: Epoch   1 Batch 3000/3125  train_loss=0.862\n",
      "2019-08-30 16:26:17: Epoch   1 Batch    0/781  test_loss=1.149\n",
      "2019-08-30 16:26:26: Epoch   1 Batch  600/781  test_loss=0.826\n",
      "2019-08-30 16:26:30: Epoch   2 Batch    0/3125  train_loss=0.902\n",
      "2019-08-30 16:26:39: Epoch   2 Batch  600/3125  train_loss=0.909\n",
      "2019-08-30 16:26:49: Epoch   2 Batch 1200/3125  train_loss=0.798\n",
      "2019-08-30 16:26:59: Epoch   2 Batch 1800/3125  train_loss=0.784\n",
      "2019-08-30 16:27:08: Epoch   2 Batch 2400/3125  train_loss=0.941\n",
      "2019-08-30 16:27:18: Epoch   2 Batch 3000/3125  train_loss=0.857\n",
      "2019-08-30 16:27:20: Epoch   2 Batch    0/781  test_loss=0.814\n",
      "2019-08-30 16:27:30: Epoch   2 Batch  600/781  test_loss=0.797\n",
      "2019-08-30 16:27:33: Epoch   3 Batch    0/3125  train_loss=0.820\n",
      "2019-08-30 16:27:43: Epoch   3 Batch  600/3125  train_loss=0.835\n",
      "2019-08-30 16:27:53: Epoch   3 Batch 1200/3125  train_loss=0.808\n",
      "2019-08-30 16:28:02: Epoch   3 Batch 1800/3125  train_loss=0.721\n",
      "2019-08-30 16:28:12: Epoch   3 Batch 2400/3125  train_loss=0.759\n",
      "2019-08-30 16:28:22: Epoch   3 Batch 3000/3125  train_loss=0.917\n",
      "2019-08-30 16:28:24: Epoch   3 Batch    0/781  test_loss=0.859\n",
      "2019-08-30 16:28:33: Epoch   3 Batch  600/781  test_loss=0.939\n",
      "2019-08-30 16:28:36: Epoch   4 Batch    0/3125  train_loss=0.768\n",
      "2019-08-30 16:28:46: Epoch   4 Batch  600/3125  train_loss=0.843\n",
      "2019-08-30 16:28:55: Epoch   4 Batch 1200/3125  train_loss=0.844\n",
      "2019-08-30 16:29:05: Epoch   4 Batch 1800/3125  train_loss=0.808\n",
      "2019-08-30 16:29:15: Epoch   4 Batch 2400/3125  train_loss=0.831\n",
      "2019-08-30 16:29:24: Epoch   4 Batch 3000/3125  train_loss=0.803\n",
      "2019-08-30 16:29:26: Epoch   4 Batch    0/781  test_loss=0.783\n",
      "2019-08-30 16:29:36: Epoch   4 Batch  600/781  test_loss=0.892\n",
      "模型已经训练完成，同时已经保存到磁盘！\n"
     ]
    }
   ],
   "source": [
    "# 训练网络\n",
    "model_path = os.path.join(file_path, \"model/model.ckpt\")  # 模型权重的保存地址\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    # 创建summary来monitor loss_op\n",
    "    loss_summary = tf.summary.scalar(\"loss\", loss_op)\n",
    "    \n",
    "    # model和summaries文件目录\n",
    "    timestamp = str(int(time.time()))\n",
    "    out_dir = os.path.join(file_path, \"runs\", timestamp)\n",
    "    print(\"目录： \", out_dir)\n",
    "    \n",
    "    # train op to write logs to Tensorboard\n",
    "    train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "    train_summary_writer = tf.summary.FileWriter(train_summary_dir, graph=sess.graph)\n",
    "    \n",
    "    # test op to write logs to Tensorboard\n",
    "    test_summary_dir = os.path.join(out_dir, \"summaries\", \"test\")\n",
    "    test_summary_writer = tf.summary.FileWriter(test_summary_dir, graph=sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Saver op to save and restore all the variables\n",
    "    saver = tf.train.Saver()\n",
    "    for epoch in range(num_epochs):\n",
    "        train, test = train_test_split(data, test_size=0.2)\n",
    "        train_batch_iterator = get_batches(train, batch_size)\n",
    "        test_batch_iterator = get_batches(test, batch_size)\n",
    "        for step in range(len(train) // batch_size):\n",
    "            batch_data = next(train_batch_iterator)\n",
    "            batchX, batchY = batch_data.drop(\"Rating\", axis=1), batch_data[\"Rating\"]\n",
    "            feed_dict = {\n",
    "                uid: np.reshape(batchX[\"UserID\"].values, [-1, 1]),\n",
    "                gender: np.reshape(batchX[\"Gender\"].values, [-1, 1]),\n",
    "                age: np.reshape(batchX[\"Age\"].values, [-1, 1]),\n",
    "                job: np.reshape(batchX[\"OccupationID\"].values, [-1, 1]),\n",
    "                mid: np.reshape(batchX[\"MovieID\"].values, [-1, 1]),\n",
    "                title: np.array(batchX[\"Title\"].values.tolist()), \n",
    "                genre: np.array(batchX[\"Genres\"].values.tolist()), \n",
    "                target: np.reshape(batchY.values, [-1, 1]),\n",
    "            }\n",
    "            summaries, loss, _, rating_score, preidct = sess.run([loss_summary, loss_op, train_op, target, inference], feed_dict=feed_dict)\n",
    "            # Write logs at every iteration(每一次迭代写一次数据)\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "#             print(rating_score[0])\n",
    "#             print(preidct[0])\n",
    "            \n",
    "            if step % display_steps == 0:\n",
    "                now_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                print(\"{}: Epoch {:>3} Batch {:>4}/{}  train_loss={:.3f}\".format(now_time, epoch, step, len(train) // batch_size, loss))\n",
    "        \n",
    "        # 进行测试\n",
    "        for step in range(len(test) // batch_size):\n",
    "            batch_data = next(test_batch_iterator)\n",
    "            batchX, batchY = batch_data.drop(\"Rating\", axis=1), batch_data[\"Rating\"]\n",
    "            feed_dict = {\n",
    "                uid: np.reshape(batchX[\"UserID\"].values, [-1, 1]),\n",
    "                gender: np.reshape(batchX[\"Gender\"].values, [-1, 1]),\n",
    "                age: np.reshape(batchX[\"Age\"].values, [-1, 1]),\n",
    "                job: np.reshape(batchX[\"OccupationID\"].values, [-1, 1]),\n",
    "                mid: np.reshape(batchX[\"MovieID\"].values, [-1, 1]),\n",
    "                title: np.array(batchX[\"Title\"].values.tolist()), \n",
    "                genre: np.array(batchX[\"Genres\"].values.tolist()), \n",
    "                target: np.reshape(batchY.values, [-1, 1]),\n",
    "            }\n",
    "            summaries, loss, _ = sess.run([loss_summary, loss_op, train_op], feed_dict=feed_dict)\n",
    "            test_summary_writer.add_summary(summaries, step)\n",
    "            \n",
    "            if step % display_steps == 0:\n",
    "                now_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                print(\"{}: Epoch {:>3} Batch {:>4}/{}  test_loss={:.3f}\".format(now_time, epoch, step, len(test) // batch_size, loss))\n",
    "                \n",
    "    # Save model weights to disk\n",
    "    saver.save(sess, save_path=model_path)\n",
    "    print(\"模型已经训练完成，同时已经保存到磁盘！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户对电影的预测评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:29:39.436576Z",
     "start_time": "2019-08-30T08:29:39.423715Z"
    }
   },
   "outputs": [],
   "source": [
    "def rating_movie(u_id, m_id):\n",
    "    \"\"\"\n",
    "    指定用户和电影进行评分\n",
    "    \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        # 构造网络图\n",
    "        saver = tf.train.import_meta_graph(os.path.join(file_path, \"model/model.ckpt.meta\"))\n",
    "        # 加载参数\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(os.path.join(file_path, \"model\")))\n",
    "        \n",
    "        u_info = data[data[\"UserID\"] == 234][[\"UserID\", \"Gender\", \"Age\", \"OccupationID\"]].iloc[[0]]\n",
    "        movie_info = data[data[\"MovieID\"] == 1401][[\"MovieID\", \"Title\", \"Genres\"]].iloc[[0]]\n",
    "        # 访问图\n",
    "        graph = tf.get_default_graph()\n",
    "    #     for op in graph.get_operations():\n",
    "    #         print(str(op.name))\n",
    "    #     print(graph.get_tensor_by_name('input_placeholder/uid:0'))\n",
    "        uid = graph.get_tensor_by_name('input_placeholder/uid:0')\n",
    "        gender = graph.get_tensor_by_name('input_placeholder/user_gender:0')\n",
    "        age = graph.get_tensor_by_name('input_placeholder/user_age:0')\n",
    "        job = graph.get_tensor_by_name('input_placeholder/user_job:0')\n",
    "        mid = graph.get_tensor_by_name('input_placeholder/mid:0')\n",
    "        title = graph.get_tensor_by_name('input_placeholder/movie_title:0')\n",
    "        genre = graph.get_tensor_by_name('input_placeholder/movie_genre:0')\n",
    "        inference = graph.get_tensor_by_name('inference:0')\n",
    "    \n",
    "        feed_dict = {\n",
    "                    uid: np.reshape(u_info[\"UserID\"].values, [-1, 1]),\n",
    "                    gender: np.reshape(u_info[\"Gender\"].values, [-1, 1]),\n",
    "                    age: np.reshape(u_info[\"Age\"].values, [-1, 1]),\n",
    "                    job: np.reshape(u_info[\"OccupationID\"].values, [-1, 1]),\n",
    "                    mid: np.reshape(movie_info[\"MovieID\"].values, [-1, 1]),\n",
    "                    title: np.array(movie_info[\"Title\"].values.tolist()), \n",
    "                    genre: np.array(movie_info[\"Genres\"].values.tolist()), \n",
    "                }\n",
    "        predict_score = sess.run([inference], feed_dict=feed_dict)\n",
    "    return predict_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:29:40.275029Z",
     "start_time": "2019-08-30T08:29:39.438616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.403473]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movie(234, 1401)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存用户和item的权重矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:29:40.289142Z",
     "start_time": "2019-08-30T08:29:40.277098Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_weights():\n",
    "    \"\"\"保存用户向量和电影向量结果\"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        # 构造网络图\n",
    "        saver = tf.train.import_meta_graph(os.path.join(file_path, \"model/model.ckpt.meta\"))\n",
    "        # 加载参数\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(os.path.join(file_path, \"model\")))\n",
    "        \n",
    "        # 访问图\n",
    "        graph = tf.get_default_graph()\n",
    "#         for op in graph.get_operations():\n",
    "#             print(str(op.name))\n",
    "\n",
    "        uid = graph.get_tensor_by_name('input_placeholder/uid:0')\n",
    "        gender = graph.get_tensor_by_name('input_placeholder/user_gender:0')\n",
    "        age = graph.get_tensor_by_name('input_placeholder/user_age:0')\n",
    "        job = graph.get_tensor_by_name('input_placeholder/user_job:0')\n",
    "        mid = graph.get_tensor_by_name('input_placeholder/mid:0')\n",
    "        title = graph.get_tensor_by_name('input_placeholder/movie_title:0')\n",
    "        genre = graph.get_tensor_by_name('input_placeholder/movie_genre:0')\n",
    "        inference = graph.get_tensor_by_name('inference:0')\n",
    "        uinfo = graph.get_tensor_by_name('user_nn/Reshape:0')\n",
    "        m_fc = graph.get_tensor_by_name('m_nn/Reshape:0')\n",
    "        print(uinfo)\n",
    "        print(m_fc)\n",
    "        \n",
    "        feed_dict = {\n",
    "                    uid: np.reshape(users[\"UserID\"].values, [-1, 1]),\n",
    "                    gender: np.reshape(users[\"Gender\"].values, [-1, 1]),\n",
    "                    age: np.reshape(users[\"Age\"].values, [-1, 1]),\n",
    "                    job: np.reshape(users[\"OccupationID\"].values, [-1, 1]),\n",
    "                    mid: np.reshape(movies[\"MovieID\"].values, [-1, 1]),\n",
    "                    title: np.array(movies[\"Title\"].values.tolist()), \n",
    "                    genre: np.array(movies[\"Genres\"].values.tolist()), \n",
    "                }\n",
    "        user_vec, movie_vec = sess.run([uinfo, m_fc], feed_dict=feed_dict)\n",
    "        np.savetxt(os.path.join(file_path, \"data_vec\", \"user_vec.txt\"), user_vec, fmt=\"%0.4f\")\n",
    "        np.savetxt(os.path.join(file_path, \"data_vec\", \"movie_vec.txt\"), movie_vec, fmt=\"%0.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:29:42.872827Z",
     "start_time": "2019-08-30T08:29:40.290902Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"user_nn/Reshape:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"m_nn/Reshape:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:43:27.609221Z",
     "start_time": "2019-08-30T08:43:27.600908Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 构建电影id和电影名称的字典表\n",
    "id2title = pd.Series(movies_source[\"Title\"].values, index=movies_source[\"MovieID\"]).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推荐相似电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:48:32.718017Z",
     "start_time": "2019-08-30T08:48:32.705210Z"
    }
   },
   "outputs": [],
   "source": [
    "def rec_similar_style(movie_id, topk=20):\n",
    "    \"\"\"推荐相似电影\"\"\"\n",
    "    # 从txt文件读取数据\n",
    "    movie_vec = tf.constant(np.loadtxt(os.path.join(file_path, \"data_vec\", \"movie_vec.txt\"), dtype=np.float32))\n",
    "    # 对向量normalize\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(movie_vec), axis=-1, keepdims=True))\n",
    "    norm_movie_vec = movie_vec / norm\n",
    "    id_vec = tf.nn.embedding_lookup(norm_movie_vec, np.array([[movie_id]]))\n",
    "    id_vec = tf.reshape(id_vec, [-1, 256])\n",
    "    probs_similarity = tf.matmul(id_vec, tf.transpose(norm_movie_vec))\n",
    "    # 取前topk的电影\n",
    "    _, indices = tf.nn.top_k(probs_similarity, k=topk, sorted=True)\n",
    "    with tf.Session() as sess:\n",
    "        indices = sess.run([indices])\n",
    "    indices = indices[0].reshape(-1).tolist()[1:]\n",
    "#     print(movies_source[movies_source[\"MovieID\"].isin(indices)][\"Title\"])\n",
    "    \n",
    "#     rec_title = movies_source[movies_source[\"MovieID\"].isin(indices)][\"Title\"].values.tolist()\n",
    "    \n",
    "    print(\"您看的电影是：{}\".format(id2title[movie_id]))\n",
    "    print(\"以下是给您的推荐：\")\n",
    "    for indice in indices:\n",
    "        print(indice, \":\", id2title[indice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:48:51.201451Z",
     "start_time": "2019-08-30T08:48:50.312765Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您看的电影是：Exit to Eden (1994)\n",
      "以下是给您的推荐：\n",
      "841 : Eyes Without a Face (1959)\n",
      "2306 : Holy Man (1998)\n",
      "877 : Girls Town (1996)\n",
      "245 : Glass Shield, The (1994)\n"
     ]
    }
   ],
   "source": [
    "indices = rec_similar_style(234, topk=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view also view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T09:17:03.857267Z",
     "start_time": "2019-08-30T09:17:03.841498Z"
    }
   },
   "outputs": [],
   "source": [
    "# 看过这个电影的人还喜欢什么电影\n",
    "def view_also_view(movie_id, topk = 20):\n",
    "    \"\"\"\n",
    "    首先选出喜欢某个电影的top_k个人，得到这几个人的用户特征向量。\n",
    "    然后计算这几个人对所有电影的评分,选择每个人评分最高的电影作为推荐,同样加入了随机选择\n",
    "    \"\"\"\n",
    "    movie_vec = tf.constant(np.loadtxt(os.path.join(file_path, \"data_vec\", \"movie_vec.txt\"), dtype=np.float32))\n",
    "    user_vec = tf.constant(np.loadtxt(os.path.join(file_path, \"data_vec\", \"user_vec.txt\"), dtype=np.float32))\n",
    "    id_vec = tf.nn.embedding_lookup(movie_vec, np.array([[movie_id]]))\n",
    "    id_vec = tf.reshape(id_vec, [-1, 256])\n",
    "    probs_similarity = tf.matmul(id_vec, tf.transpose(user_vec))\n",
    "    _, indices = tf.nn.top_k(probs_similarity, k=topk, sorted=True)\n",
    "    indices = tf.reshape(indices, [-1, 1])\n",
    "    top_user_vec = tf.nn.embedding_lookup(user_vec, indices)\n",
    "    top_user_vec = tf.reshape(top_user_vec, [-1, 256])\n",
    "    \n",
    "    sim_dist = tf.matmul(top_user_vec, tf.transpose(movie_vec))\n",
    "    \n",
    "    _, top_indices = tf.nn.top_k(sim_dist, k=2)\n",
    "    top_indices = tf.reshape(top_indices, [-1])\n",
    "    with tf.Session() as sess:\n",
    "        indices = sess.run([top_indices])\n",
    "    indices = indices[0].tolist()[1:]\n",
    "    \n",
    "    print(\"看过的电影是：{}\".format(id2title[movie_id]))\n",
    "    print(\"看过这个电影的人还喜欢什么电影：\")\n",
    "    for indice in indices:\n",
    "        print(indice, \":\", id2title[indice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T09:17:06.615023Z",
     "start_time": "2019-08-30T09:17:04.640296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看过的电影是：Ghosts of Mississippi (1996)\n",
      "看过这个电影的人还喜欢什么电影：\n",
      "540 : Sliver (1993)\n",
      "2502 : Office Space (1999)\n",
      "2284 : Bandit Queen (1994)\n",
      "3375 : Destination Moon (1950)\n",
      "3339 : Cross of Iron (1977)\n",
      "3020 : Falling Down (1993)\n",
      "2872 : Excalibur (1981)\n",
      "148 : Awfully Big Adventure, An (1995)\n",
      "257 : Just Cause (1995)\n"
     ]
    }
   ],
   "source": [
    "view_also_view(1401, topk = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (tfproject)",
   "language": "python",
   "name": "tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "1. 生成配置文件\n",
     "jupyter notebook --generate-config\n",
     "2. 生成登陆密码\n",
     "from notebook.auth import passwd\n",
     "passwd()\n",
     "会输出如下：\n",
     "Out[2]: 'sha1:5311cd8b9da9:70dd3321fccb5b5d77e66080a5d3d943ab9752b4'\n",
     "3. 修改配置文件\n",
     "vim ~/.jupyter/jupyter_notebook_config.py\n",
     "c.NotebookApp.ip='0.0.0.0'\n",
     "c.NotebookApp.password = u'sha1:5311cd8b9da9:70dd3321fccb5b5d77e66080a5d3d943ab9752b4'\n",
     "c.NotebookApp.open_browser = False\n",
     "c.NotebookApp.port =8888    #随便指定一个端口，使用默认8888也可以\n",
     "4. 配置kernel\n",
     "python -m ipykernel install --user --name tf3 --display-name \"PyCharm (tfproject)\""
    ]
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
